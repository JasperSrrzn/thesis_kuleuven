

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Introduction by example &mdash; pytorch_geometric master documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Creating message passing networks" href="create_gnn.html" />
    <link rel="prev" title="Installation" href="installation.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/pyg_logo_text.svg" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                master (1.2.0)
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="installation.html#c-cuda-extensions-on-macos">C++/CUDA Extensions on macOS</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#id1">Frequently Asked Questions</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Introduction by example</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#data-handling-of-graphs">Data handling of graphs</a></li>
<li class="toctree-l2"><a class="reference internal" href="#common-benchmark-datasets">Common benchmark datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="#mini-batches">Mini-batches</a></li>
<li class="toctree-l2"><a class="reference internal" href="#data-transforms">Data transforms</a></li>
<li class="toctree-l2"><a class="reference internal" href="#learning-methods-on-graphs">Learning methods on graphs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="create_gnn.html">Creating message passing networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="create_gnn.html#the-messagepassing-base-class">The “MessagePassing” base class</a></li>
<li class="toctree-l2"><a class="reference internal" href="create_gnn.html#implementing-the-gcn-layer">Implementing the GCN layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="create_gnn.html#implementing-the-edge-convolution">Implementing the edge convolution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="create_dataset.html">Creating your own datasets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="create_dataset.html#creating-in-memory-datasets">Creating “in memory datasets”</a></li>
<li class="toctree-l2"><a class="reference internal" href="create_dataset.html#creating-larger-datasets">Creating “larger” datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="create_dataset.html#frequently-asked-questions">Frequently Asked Questions</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../modules/nn.html">torch_geometric.nn</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../modules/nn.html#module-torch_geometric.nn.conv.message_passing">Convolutional Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../modules/nn.html#module-torch_geometric.nn.glob">Global Pooling Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../modules/nn.html#module-torch_geometric.nn.pool">Pooling Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../modules/nn.html#module-torch_geometric.nn.unpool">Unpooling Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../modules/nn.html#module-torch_geometric.nn.models">Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../modules/nn.html#module-torch_geometric.nn.data_parallel">DataParallel layers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../modules/data.html">torch_geometric.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/datasets.html">torch_geometric.datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/transforms.html">torch_geometric.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/utils.html">torch_geometric.utils</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">pytorch_geometric</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Introduction by example</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/notes/introduction.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="introduction-by-example">
<h1>Introduction by example<a class="headerlink" href="#introduction-by-example" title="Permalink to this headline">¶</a></h1>
<p>We shortly introduce the fundamental concepts of <a class="reference external" href="https://github.com/rusty1s/pytorch_geometric">PyTorch Geometric</a> through self-contained examples.
At its core, PyTorch Geometric provides the following main features:</p>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><a class="reference internal" href="#data-handling-of-graphs" id="id1">Data handling of graphs</a></li>
<li><a class="reference internal" href="#common-benchmark-datasets" id="id2">Common benchmark datasets</a></li>
<li><a class="reference internal" href="#mini-batches" id="id3">Mini-batches</a></li>
<li><a class="reference internal" href="#data-transforms" id="id4">Data transforms</a></li>
<li><a class="reference internal" href="#learning-methods-on-graphs" id="id5">Learning methods on graphs</a></li>
</ul>
</div>
<div class="section" id="data-handling-of-graphs">
<h2><a class="toc-backref" href="#id1">Data handling of graphs</a><a class="headerlink" href="#data-handling-of-graphs" title="Permalink to this headline">¶</a></h2>
<p>A graph is used to model pairwise relations (edges) between objects (nodes).
A single graph in PyTorch Geometric is described by an instance of <a class="reference internal" href="../modules/data.html#torch_geometric.data.Data" title="torch_geometric.data.Data"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.data.Data</span></code></a>, which holds the following attributes by default:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">data.x</span></code>: Node feature matrix with shape <code class="docutils literal notranslate"><span class="pre">[num_nodes,</span> <span class="pre">num_node_features]</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">data.edge_index</span></code>: Graph connectivity in COO format with shape <code class="docutils literal notranslate"><span class="pre">[2,</span> <span class="pre">num_edges]</span></code> and type <code class="docutils literal notranslate"><span class="pre">torch.long</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">data.edge_attr</span></code>: Edge feature matrix with shape <code class="docutils literal notranslate"><span class="pre">[num_edges,</span> <span class="pre">num_edge_features]</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">data.y</span></code>: Target to train against (may have arbitrary shape)</li>
<li><code class="docutils literal notranslate"><span class="pre">data.pos</span></code>: Node position matrix with shape <code class="docutils literal notranslate"><span class="pre">[num_nodes,</span> <span class="pre">num_dimensions]</span></code></li>
</ul>
<p>None of these attributes is required.
In fact, the <code class="docutils literal notranslate"><span class="pre">Data</span></code> object is not even restricted to these attributes.
We can, <em>e.g.</em>, extend it by <code class="docutils literal notranslate"><span class="pre">data.face</span></code> to save the connectivity of triangles from a 3D mesh in a tensor with shape <code class="docutils literal notranslate"><span class="pre">[3,</span> <span class="pre">num_faces]</span></code> and type <code class="docutils literal notranslate"><span class="pre">torch.long</span></code>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">PyTorch and <code class="docutils literal notranslate"><span class="pre">torchvision</span></code> define an example as a tuple of an image and a target.
We omit this notation in PyTorch Geometric to allow for various data structures in a clean and understandable way.</p>
</div>
<p>We show a simple example of an unweighted and undirected graph with three nodes and four edges.
Each node contains exactly one feature:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch_geometric.data</span> <span class="kn">import</span> <span class="n">Data</span>

<span class="n">edge_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                           <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">Data</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="o">=</span><span class="n">edge_index</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">Data</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">edge_index</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/graph.svg"><div align="center" class="align-center"><img alt="../_images/graph.svg" src="../_images/graph.svg" width="300px" /></div>
</a>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p>Note that <code class="docutils literal notranslate"><span class="pre">edge_index</span></code>, <em>i.e.</em> the tensor defining the source and target nodes of all edges, is NOT a list of index tuples.
If you want to write your indices this way, you should transpose and call <code class="docutils literal notranslate"><span class="pre">contiguous</span></code> on it before passing them to the data constructor:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch_geometric.data</span> <span class="kn">import</span> <span class="n">Data</span>

<span class="n">edge_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                           <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                           <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                           <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">Data</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="o">=</span><span class="n">edge_index</span><span class="o">.</span><span class="n">t</span><span class="p">()</span><span class="o">.</span><span class="n">contiguous</span><span class="p">())</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">Data</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">edge_index</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
</pre></div>
</div>
<p>Although the graph has only two edges, we need to define four index tuples to account for both directions of a edge.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">You can print out your data object anytime and receive a short information about its attributes and their shapes.</p>
</div>
<p>Besides of being a plain old python object, <a class="reference internal" href="../modules/data.html#torch_geometric.data.Data" title="torch_geometric.data.Data"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.data.Data</span></code></a> provides a number of utility functions, <em>e.g.</em>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;edge_index&#39;</span><span class="p">]</span>

<span class="k">print</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tensor</span><span class="p">([[</span><span class="mf">0.0</span><span class="p">],</span>
            <span class="p">[</span><span class="mf">1.0</span><span class="p">],</span>
            <span class="p">[</span><span class="mf">2.0</span><span class="p">]])</span>

<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;{} found in data)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="n">found</span> <span class="ow">in</span> <span class="n">data</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">edge_index</span> <span class="n">found</span> <span class="ow">in</span> <span class="n">data</span>

<span class="s1">&#39;edge_attr&#39;</span> <span class="ow">in</span> <span class="n">data</span>
<span class="o">&gt;&gt;&gt;</span> <span class="bp">False</span>

<span class="n">data</span><span class="o">.</span><span class="n">num_nodes</span>
<span class="o">&gt;&gt;&gt;</span> <span class="mi">3</span>

<span class="n">data</span><span class="o">.</span><span class="n">num_edges</span>
<span class="o">&gt;&gt;&gt;</span> <span class="mi">4</span>

<span class="n">data</span><span class="o">.</span><span class="n">num_features</span>
<span class="o">&gt;&gt;&gt;</span> <span class="mi">1</span>

<span class="n">data</span><span class="o">.</span><span class="n">contains_isolated_nodes</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="bp">False</span>

<span class="n">data</span><span class="o">.</span><span class="n">contains_self_loops</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="bp">False</span>

<span class="n">data</span><span class="o">.</span><span class="n">is_directed</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="bp">False</span>

<span class="c1"># Transfer data object to GPU.</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p>You can find a complete list of all methods at <a class="reference internal" href="../modules/data.html#torch_geometric.data.Data" title="torch_geometric.data.Data"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.data.Data</span></code></a>.</p>
</div>
<div class="section" id="common-benchmark-datasets">
<h2><a class="toc-backref" href="#id2">Common benchmark datasets</a><a class="headerlink" href="#common-benchmark-datasets" title="Permalink to this headline">¶</a></h2>
<p>PyTorch Geometric contains a large number of common benchmark datasets, <em>e.g.</em> all Planetoid datasets (Cora, Citeseer, Pubmed), all graph classification datasets from <a class="reference external" href="http://graphkernels.cs.tu-dortmund.de/">http://graphkernels.cs.tu-dortmund.de/</a>, the QM7 and QM9 dataset, and a handful of 3D mesh/point cloud datasets like FAUST, ModelNet10/40 and ShapeNet.</p>
<p>Initializing a dataset is straightforward.
An initialization of a dataset will automatically download its raw files and process them to the previously described <code class="docutils literal notranslate"><span class="pre">Data</span></code> format.
<em>E.g.</em>, to load the ENZYMES dataset (consisting of 600 graphs within 6 classes), type:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch_geometric.datasets</span> <span class="kn">import</span> <span class="n">TUDataset</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">TUDataset</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;/tmp/ENZYMES&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;ENZYMES&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ENZYMES</span><span class="p">(</span><span class="mi">600</span><span class="p">)</span>

<span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="mi">600</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">num_classes</span>
<span class="o">&gt;&gt;&gt;</span> <span class="mi">6</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">num_features</span>
<span class="o">&gt;&gt;&gt;</span> <span class="mi">21</span>
</pre></div>
</div>
<p>We now have access to all 600 graphs in the dataset:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">Data</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="p">[</span><span class="mi">37</span><span class="p">,</span> <span class="mi">21</span><span class="p">],</span> <span class="n">edge_index</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">168</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="n">data</span><span class="o">.</span><span class="n">is_undirected</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="bp">True</span>
</pre></div>
</div>
<p>We can see that the first graph in the dataset contains 37 nodes, each one having 21 features.
There are 168/2 = 84 undirected edges and the graph is assigned to exactly one class.</p>
<p>We can even use slices, long or byte tensors to split the dataset.
<em>E.g.</em>, to create a 90/10 train/test split, type:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:</span><span class="mi">540</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ENZYMES</span><span class="p">(</span><span class="mi">540</span><span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">540</span><span class="p">:]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ENZYMES</span><span class="p">(</span><span class="mi">60</span><span class="p">)</span>
</pre></div>
</div>
<p>If you are unsure whether the dataset is already shuffled before you split, you can randomly permutate it by running:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">shuffle</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ENZYMES</span><span class="p">(</span><span class="mi">600</span><span class="p">)</span>
</pre></div>
</div>
<p>This is equivalent of doing:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">perm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">perm</span><span class="p">]</span>
<span class="o">&gt;&gt;</span> <span class="n">ENZYMES</span><span class="p">(</span><span class="mi">600</span><span class="p">)</span>
</pre></div>
</div>
<p>Let’s try another one! Let’s download Cora, the standard benchmark dataset for semi-supervised graph node classification:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch_geometric.datasets</span> <span class="kn">import</span> <span class="n">Planetoid</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">Planetoid</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;/tmp/Cora&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Cora&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">Cora</span><span class="p">()</span>

<span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="mi">1</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">num_classes</span>
<span class="o">&gt;&gt;&gt;</span> <span class="mi">7</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">num_features</span>
<span class="o">&gt;&gt;&gt;</span> <span class="mi">1433</span>
</pre></div>
</div>
<p>Here, the dataset contains only a single, undirected citation graph:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">Data</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="p">[</span><span class="mi">2708</span><span class="p">,</span> <span class="mi">1433</span><span class="p">],</span> <span class="n">edge_index</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10556</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="p">[</span><span class="mi">2708</span><span class="p">],</span>
         <span class="n">train_mask</span><span class="o">=</span><span class="p">[</span><span class="mi">2708</span><span class="p">],</span> <span class="n">val_mask</span><span class="o">=</span><span class="p">[</span><span class="mi">2708</span><span class="p">],</span> <span class="n">test_mask</span><span class="o">=</span><span class="p">[</span><span class="mi">2708</span><span class="p">])</span>

<span class="n">data</span><span class="o">.</span><span class="n">is_undirected</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="bp">True</span>

<span class="n">data</span><span class="o">.</span><span class="n">train_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="mi">140</span>

<span class="n">data</span><span class="o">.</span><span class="n">val_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="mi">500</span>

<span class="n">data</span><span class="o">.</span><span class="n">test_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="mi">1000</span>
</pre></div>
</div>
<p>This time, the <code class="docutils literal notranslate"><span class="pre">Data</span></code> objects holds additional attributes: <code class="docutils literal notranslate"><span class="pre">train_mask</span></code>, <code class="docutils literal notranslate"><span class="pre">val_mask</span></code> and <code class="docutils literal notranslate"><span class="pre">test_mask</span></code>:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">train_mask</span></code> denotes against which nodes to train (140 nodes)</li>
<li><code class="docutils literal notranslate"><span class="pre">val_mask</span></code> denotes which nodes to use for validation, <em>e.g.</em>, to perform early stopping (500 nodes)</li>
<li><code class="docutils literal notranslate"><span class="pre">test_mask</span></code> denotes against which nodes to test (1000 nodes)</li>
</ul>
</div>
<div class="section" id="mini-batches">
<h2><a class="toc-backref" href="#id3">Mini-batches</a><a class="headerlink" href="#mini-batches" title="Permalink to this headline">¶</a></h2>
<p>Neural networks are usually trained in a batch-wise fashion.
PyTorch Geometric achieves parallelization over a mini-batch by creating sparse block diagonal adjacency matrices (defined by <code class="docutils literal notranslate"><span class="pre">edge_index</span></code> and <code class="docutils literal notranslate"><span class="pre">edge_attr</span></code>) and concatenating feature and target matrices in the node dimension.
This composition allows differing number of nodes and edges over examples in one batch:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf{A} = \begin{bmatrix} \mathbf{A}_1 &amp; &amp; \\ &amp; \ddots &amp; \\ &amp; &amp; \mathbf{A}_n \end{bmatrix}, \qquad \mathbf{X} = \begin{bmatrix} \mathbf{X}_1 \\ \vdots \\ \mathbf{X}_n \end{bmatrix}, \qquad \mathbf{Y} = \begin{bmatrix} \mathbf{Y}_1 \\ \vdots \\ \mathbf{Y}_n \end{bmatrix}\end{split}\]</div>
<p>PyTorch Geometric contains its own <a class="reference internal" href="../modules/data.html#torch_geometric.data.DataLoader" title="torch_geometric.data.DataLoader"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.data.DataLoader</span></code></a>, which already takes care of this concatenation process.
Let’s learn about it in an example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch_geometric.datasets</span> <span class="kn">import</span> <span class="n">TUDataset</span>
<span class="kn">from</span> <span class="nn">torch_geometric.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">TUDataset</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;/tmp/ENZYMES&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;ENZYMES&#39;</span><span class="p">)</span>
<span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
    <span class="n">batch</span>
    <span class="o">&gt;&gt;&gt;</span> <span class="n">Batch</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="p">[</span><span class="mi">1082</span><span class="p">,</span> <span class="mi">21</span><span class="p">],</span> <span class="n">edge_index</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4066</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">],</span> <span class="n">batch</span><span class="o">=</span><span class="p">[</span><span class="mi">1082</span><span class="p">])</span>

    <span class="n">batch</span><span class="o">.</span><span class="n">num_graphs</span>
    <span class="o">&gt;&gt;&gt;</span> <span class="mi">32</span>
</pre></div>
</div>
<p><a class="reference internal" href="../modules/data.html#torch_geometric.data.Batch" title="torch_geometric.data.Batch"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.data.Batch</span></code></a> inherits from <a class="reference internal" href="../modules/data.html#torch_geometric.data.Data" title="torch_geometric.data.Data"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.data.Data</span></code></a> and contains an additional attribute: <code class="docutils literal notranslate"><span class="pre">batch</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">batch</span></code> is a column vector of graph identifiers for all nodes of all graphs in the batch:</p>
<div class="math notranslate nohighlight">
\[\mathrm{batch} = {\begin{bmatrix} 0 &amp; \cdots &amp; 0 &amp; 1 &amp; \cdots &amp; n - 2 &amp; n -1 &amp; \cdots &amp; n - 1 \end{bmatrix}}^{\top}\]</div>
<p>You can use it to, <em>e.g.</em>, average node features in the node dimension for each graph individually:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch_scatter</span> <span class="kn">import</span> <span class="n">scatter_mean</span>
<span class="kn">from</span> <span class="nn">torch_geometric.datasets</span> <span class="kn">import</span> <span class="n">TUDataset</span>
<span class="kn">from</span> <span class="nn">torch_geometric.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">TUDataset</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;/tmp/ENZYMES&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;ENZYMES&#39;</span><span class="p">)</span>
<span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
    <span class="n">data</span>
    <span class="o">&gt;&gt;&gt;</span> <span class="n">Batch</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="p">[</span><span class="mi">1082</span><span class="p">,</span> <span class="mi">21</span><span class="p">],</span> <span class="n">edge_index</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4066</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">],</span> <span class="n">batch</span><span class="o">=</span><span class="p">[</span><span class="mi">1082</span><span class="p">])</span>

    <span class="n">data</span><span class="o">.</span><span class="n">num_graphs</span>
    <span class="o">&gt;&gt;&gt;</span> <span class="mi">32</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">scatter_mean</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
    <span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">32</span><span class="p">,</span> <span class="mi">21</span><span class="p">])</span>
</pre></div>
</div>
<p>You can learn more about scatter operations in the <a class="reference external" href="http://rusty1s.github.io/pytorch_scatter">documentation</a> of <code class="docutils literal notranslate"><span class="pre">torch_scatter</span></code>.</p>
</div>
<div class="section" id="data-transforms">
<h2><a class="toc-backref" href="#id4">Data transforms</a><a class="headerlink" href="#data-transforms" title="Permalink to this headline">¶</a></h2>
<p>Transforms are a common way in <code class="docutils literal notranslate"><span class="pre">torchvision</span></code> to transform images and perform augmentation.
PyTorch Geometric comes with its own transforms, which expect a <code class="docutils literal notranslate"><span class="pre">Data</span></code> object as input and return a new transformed <code class="docutils literal notranslate"><span class="pre">Data</span></code> object.
Transforms can be chained together using <a class="reference internal" href="../modules/transforms.html#torch_geometric.transforms.Compose" title="torch_geometric.transforms.Compose"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.transforms.Compose</span></code></a> and are applied before saving a processed dataset on disk (<code class="docutils literal notranslate"><span class="pre">pre_transform</span></code>) or before accessing a graph in a dataset (<code class="docutils literal notranslate"><span class="pre">transform</span></code>).</p>
<p>Let’s look at an example, where we apply transforms on the ShapeNet dataset (containing 17,000 3D shape point clouds and per point labels from 16 shape categories).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch_geometric.datasets</span> <span class="kn">import</span> <span class="n">ShapeNet</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">ShapeNet</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;/tmp/ShapeNet&#39;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="s1">&#39;Airplane&#39;</span><span class="p">)</span>

<span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">Data</span><span class="p">(</span><span class="n">pos</span><span class="o">=</span><span class="p">[</span><span class="mi">2518</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="p">[</span><span class="mi">2518</span><span class="p">])</span>
</pre></div>
</div>
<p>We can convert the point cloud dataset into a graph dataset by generating nearest neighbor graphs from the point clouds via transforms:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch_geometric.transforms</span> <span class="kn">as</span> <span class="nn">T</span>
<span class="kn">from</span> <span class="nn">torch_geometric.datasets</span> <span class="kn">import</span> <span class="n">ShapeNet</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">ShapeNet</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;/tmp/ShapeNet&#39;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="s1">&#39;Airplane&#39;</span><span class="p">,</span>
                    <span class="n">pre_transform</span><span class="o">=</span><span class="n">T</span><span class="o">.</span><span class="n">KNNGraph</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">6</span><span class="p">))</span>

<span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">Data</span><span class="p">(</span><span class="n">edge_index</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">17768</span><span class="p">],</span> <span class="n">pos</span><span class="o">=</span><span class="p">[</span><span class="mi">2518</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="p">[</span><span class="mi">2518</span><span class="p">])</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">We use the <code class="docutils literal notranslate"><span class="pre">pre_transform</span></code> to convert the data before saving it to disk (leading to faster loading times).
Note that the next time the dataset is initialized it will already contain graph edges, even if you do not pass any transform.</p>
</div>
<p>In addition, we can use the <code class="docutils literal notranslate"><span class="pre">transform</span></code> argument to randomly augment a <code class="docutils literal notranslate"><span class="pre">Data</span></code> object, <em>e.g.</em> translating each node position by a small number:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch_geometric.transforms</span> <span class="kn">as</span> <span class="nn">T</span>
<span class="kn">from</span> <span class="nn">torch_geometric.datasets</span> <span class="kn">import</span> <span class="n">ShapeNet</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">ShapeNet</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;/tmp/ShapeNet&#39;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="s1">&#39;Airplane&#39;</span><span class="p">,</span>
                    <span class="n">pre_transform</span><span class="o">=</span><span class="n">T</span><span class="o">.</span><span class="n">NNGraph</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">6</span><span class="p">),</span>
                    <span class="n">transform</span><span class="o">=</span><span class="n">T</span><span class="o">.</span><span class="n">RandomTranslate</span><span class="p">(</span><span class="mf">0.01</span><span class="p">))</span>

<span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">Data</span><span class="p">(</span><span class="n">edge_index</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">17768</span><span class="p">],</span> <span class="n">pos</span><span class="o">=</span><span class="p">[</span><span class="mi">2518</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="p">[</span><span class="mi">2518</span><span class="p">])</span>
</pre></div>
</div>
<p>You can find a complete list of all implemented transforms at <a class="reference internal" href="../modules/transforms.html#module-torch_geometric.transforms" title="torch_geometric.transforms"><code class="xref py py-mod docutils literal notranslate"><span class="pre">torch_geometric.transforms</span></code></a>.</p>
</div>
<div class="section" id="learning-methods-on-graphs">
<h2><a class="toc-backref" href="#id5">Learning methods on graphs</a><a class="headerlink" href="#learning-methods-on-graphs" title="Permalink to this headline">¶</a></h2>
<p>After learning about data handling, datasets, loader and transforms in PyTorch Geometric, it’s time to implement our first graph neural network!</p>
<p>We will use a simple GCN layer and replicate the experiments on the Cora citation dataset.
For a high-level explanation on GCN, have a look at its <a class="reference external" href="http://tkipf.github.io/graph-convolutional-networks/">blog post</a>.</p>
<p>We first need to load the Cora dataset:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch_geometric.datasets</span> <span class="kn">import</span> <span class="n">Planetoid</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">Planetoid</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;/tmp/Cora&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Cora&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">Cora</span><span class="p">()</span>
</pre></div>
</div>
<p>Note that we do not need to use transforms or a dataloader.
Now let’s implement a two-layer GCN:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="kn">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">GCNConv</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">GCNConv</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">num_features</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">GCNConv</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">num_classes</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">edge_index</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>We use ReLU as our non-linear activation function and output a softmax distribution over the number of classes.
Let’s train this model on the train nodes for 200 epochs:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">200</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">nll_loss</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">train_mask</span><span class="p">],</span> <span class="n">data</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">train_mask</span><span class="p">])</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
<p>Finally we can evaluate our model on the test nodes:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">_</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">correct</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">test_mask</span><span class="p">]</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">test_mask</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="n">acc</span> <span class="o">=</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">data</span><span class="o">.</span><span class="n">test_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Accuracy: {:.4f}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">0.8150</span>
</pre></div>
</div>
<p>That is all it takes to implement your first graph neural network.
The easiest way to learn more about graph convolution and pooling is to study the examples in the <code class="docutils literal notranslate"><span class="pre">examples/</span></code> directory and to browse <code class="xref py py-mod docutils literal notranslate"><span class="pre">torch_geometric.nn</span></code>.
Happy hacking!</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="create_gnn.html" class="btn btn-neutral float-right" title="Creating message passing networks" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="installation.html" class="btn btn-neutral float-left" title="Installation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Matthias Fey

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>